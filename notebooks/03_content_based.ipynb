{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ccb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce1d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "games =  pd.read_parquet('../data/cleaned/games_cleaned.parquet')\n",
    "test_df = pd.read_parquet('../data/cleaned/test_recommendations.parquet')\n",
    "train_df = pd.read_parquet('../data/cleaned/train_recommendations.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a28c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = train_df['user_id'].unique()\n",
    "unique_items = games['app_id'].unique()\n",
    "\n",
    "user_to_idx = {uid: idx for idx, uid in enumerate(unique_users)}\n",
    "item_to_idx = {iid: idx for idx, iid in enumerate(unique_items)}\n",
    "idx_to_user = {idx: uid for uid, idx in user_to_idx.items()}\n",
    "idx_to_item = {idx: iid for iid, idx in item_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da80ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "games['content'] = games['title'] + ' ' + games['description'] + ' ' + games['tags'].apply(lambda tags: ' '.join(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6c5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(games['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9604be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/tfidf_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ae3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Funzione per raccomandare giochi simili con le distanze (similarità)\n",
    "def recommend_content_based(game_id, N=10):\n",
    "    \n",
    "    game_idx = item_to_idx[game_id]\n",
    "    \n",
    "    # Estrai il vettore del gioco per cui vogliamo le raccomandazioni\n",
    "    game_vector = tfidf_matrix[game_idx]\n",
    "    \n",
    "    # Calcola la similarità coseno tra il vettore del gioco richiesto e tutti gli altri\n",
    "    similarity_scores = cosine_similarity(game_vector.reshape(1, -1), tfidf_matrix)[0]\n",
    "    \n",
    "    # Ordina i giochi per similarità decrescente\n",
    "    similar_indices = similarity_scores.argsort()[::-1][1:N+1]  # Ignora il gioco stesso\n",
    "    \n",
    "    # Ottieni gli app_id dei giochi più simili e le loro distanze (similarità)\n",
    "    recommended_game_ids = games['app_id'].iloc[similar_indices].tolist()\n",
    "    recommended_distances = similarity_scores[similar_indices].tolist()\n",
    "    \n",
    "    return recommended_game_ids, recommended_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "983ea720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game being considered: Soccer Manager 2020\n",
      "Recommended games:\n",
      "- Pro 11 - Football Manager Game\n",
      "- Soccer Manager 2021\n",
      "- WE ARE FOOTBALL\n",
      "- New Star Manager\n",
      "- Soccer Manager 2022\n",
      "- Football Manager 2023\n",
      "- Futuball - Future Football Manager Game\n",
      "- Club Manager 2016\n",
      "- Football Manager 2020 In-game Editor\n",
      "- Crazy Soccer: Football Stars\n"
     ]
    }
   ],
   "source": [
    "# Ora fuori dalla funzione, otteniamo i nomi dei giochi:\n",
    "current_game_name = games[games['app_id'] == 1078730]['title'].values[0]\n",
    "recommended_games, recommended_distances = recommend_content_based(1078730, N=10)\n",
    "# Ottieni i nomi dei giochi raccomandati\n",
    "recommended_game_names = games[games['app_id'].isin(recommended_games)]['title'].tolist()\n",
    "\n",
    "# Stampa il risultato\n",
    "print(f\"Game being considered: {current_game_name}\")\n",
    "print(\"Recommended games:\")\n",
    "for game in recommended_game_names:\n",
    "    print(f\"- {game}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de467ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_for_user(user_id, N=10):\n",
    "    recommended_games_dict = {}\n",
    "\n",
    "    # Itera su tutti i giochi con cui l'utente ha interagito\n",
    "    for game_id in train_df[train_df['user_id'] == user_id]['app_id']:\n",
    "        # Ottieni le raccomandazioni per il gioco corrente\n",
    "        recommended_games, recommended_similarity = recommend_content_based(game_id, N=10)\n",
    "        \n",
    "        # Aggiungi le raccomandazioni al dizionario, escludendo il gioco stesso\n",
    "        for rec_game_id, similarity in zip(recommended_games, recommended_similarity):\n",
    "            if rec_game_id != game_id:  # Escludi il gioco stesso\n",
    "                if rec_game_id not in recommended_games_dict:\n",
    "                    recommended_games_dict[rec_game_id] = similarity\n",
    "                else:\n",
    "                    # Mantieni solo la similarità più alta per ogni gioco\n",
    "                    recommended_games_dict[rec_game_id] = max(recommended_games_dict[rec_game_id], similarity)\n",
    "\n",
    "    # Ordina i giochi in base alla similarità e prendi i primi N\n",
    "    sorted_recommendations = sorted(recommended_games_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Torna i primi N giochi distinti\n",
    "    top_n_games = sorted_recommendations[:N]\n",
    "    \n",
    "    return top_n_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a658595d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game ID: 49520, Similarity: 1.0000\n",
      "Game ID: 744680, Similarity: 0.8958\n",
      "Game ID: 1390710, Similarity: 0.8750\n",
      "Game ID: 1283090, Similarity: 0.8111\n",
      "Game ID: 330830, Similarity: 0.7590\n",
      "Game ID: 2199500, Similarity: 0.7360\n",
      "Game ID: 801860, Similarity: 0.7320\n",
      "Game ID: 1517481, Similarity: 0.7268\n",
      "Game ID: 1946960, Similarity: 0.7126\n",
      "Game ID: 1454970, Similarity: 0.7120\n"
     ]
    }
   ],
   "source": [
    "# Testa la funzione\n",
    "user_id = 8392451  # Usa un esempio di user_id\n",
    "recommended_games = get_recommendations_for_user(user_id, N=10)\n",
    "for game, similarity in recommended_games:\n",
    "    print(f\"Game ID: {game}, Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84c39418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ottieni gli utenti presenti nel test set e nel train set come set per una ricerca più veloce\n",
    "test_users_set = set(test_df['user_id'].unique())\n",
    "train_users_set = set(train_df['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f86fb60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_users = list(test_users_set & train_users_set)  # Intersezione come lista\n",
    "cold_start_users = list(test_users_set - train_users_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "323e6798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utenti noti con almeno 10 righe nel test set: 15029\n"
     ]
    }
   ],
   "source": [
    "# Conta il numero di righe per ogni user_id nel test set\n",
    "user_counts = test_df.groupby('user_id').size()\n",
    "\n",
    "# Filtra gli utenti che hanno almeno 10 righe\n",
    "known_users_filtered = [user_id for user_id in known_users if user_counts[user_id] >= 10]\n",
    "\n",
    "# Stampa gli utenti filtrati\n",
    "print(f\"Utenti noti con almeno 10 righe nel test set: {len(known_users_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2ff85e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisione per l'utente 22: 0.0\n",
      "Recall per l'utente 22: 0.0\n",
      "F1-Score per l'utente 22: 0\n",
      "Hit Ratio per l'utente 22: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Funzione per calcolare la precisione\n",
    "def calculate_precision(user_id, recommended_items, test_df):\n",
    "    # Ottieni gli articoli effettivi con cui l'utente ha interagito nel test set (dove is_recommended == 1)\n",
    "    actual_items = test_df[(test_df['user_id'] == user_id) & (test_df['is_recommended'] == 1)]['app_id']\n",
    "    \n",
    "    # Confronta gli articoli raccomandati con quelli effettivi\n",
    "    recommended_item_ids = [item[0] for item in recommended_items]\n",
    "    \n",
    "    # Calcola la precisione come frazione di articoli raccomandati che sono effettivamente rilevanti\n",
    "    relevant_recommendations = sum(1 for item in recommended_item_ids if item in actual_items.values)\n",
    "    precision = relevant_recommendations / len(recommended_item_ids) if len(recommended_item_ids) > 0 else 0\n",
    "    \n",
    "    return precision\n",
    "\n",
    "# Funzione per calcolare il recall\n",
    "def calculate_recall(user_id, recommended_items, test_df):\n",
    "    # Ottieni gli articoli effettivi con cui l'utente ha interagito nel test set (dove is_recommended == 1)\n",
    "    actual_items = test_df[(test_df['user_id'] == user_id) & (test_df['is_recommended'] == 1)]['app_id']\n",
    "    \n",
    "    # Confronta gli articoli raccomandati con quelli effettivi\n",
    "    recommended_item_ids = [item[0] for item in recommended_items]\n",
    "    \n",
    "    # Calcola il recall come frazione di articoli rilevanti che sono stati raccomandati\n",
    "    relevant_recommendations = sum(1 for item in recommended_item_ids if item in actual_items.values)\n",
    "    recall = relevant_recommendations / len(actual_items) if len(actual_items) > 0 else 0\n",
    "    \n",
    "    return recall\n",
    "\n",
    "# Funzione per calcolare il F1-Score\n",
    "def calculate_f1_score(user_id, recommended_items, test_df):\n",
    "    precision = calculate_precision(user_id, recommended_items, test_df)\n",
    "    recall = calculate_recall(user_id, recommended_items, test_df)\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def calculate_hit_ratio(user_id, recommended_items, test_df, N=10):\n",
    "    actual_items = test_df[(test_df['user_id'] == user_id) & (test_df['is_recommended'] == 1)]['app_id']\n",
    "    recommended_item_ids = [item[0] for item in recommended_items][:N]  # Limita alle prime N raccomandazioni\n",
    "    hit = 1 if any(item in actual_items.values for item in recommended_item_ids) else 0\n",
    "    return hit\n",
    "\n",
    "user_id = 22  # esempio di user_id nel test set\n",
    "recommended_items = get_recommendations_for_user(user_id)\n",
    "\n",
    "# Calcola la precisione, recall e F1-Score\n",
    "precision = calculate_precision(user_id, recommended_items, test_df)\n",
    "recall = calculate_recall(user_id, recommended_items, test_df)\n",
    "f1 = calculate_f1_score(user_id, recommended_items, test_df)\n",
    "hit = calculate_hit_ratio(user_id, recommended_items, test_df)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(f\"Precisione per l'utente {user_id}: {precision}\")\n",
    "print(f\"Recall per l'utente {user_id}: {recall}\")\n",
    "print(f\"F1-Score per l'utente {user_id}: {f1}\")\n",
    "print(f\"Hit Ratio per l'utente {user_id}: {hit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28583870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:12<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "known_user_metrics = []\n",
    "for user_id in tqdm(known_users_filtered[0:100]):\n",
    "    recommended_items = get_recommendations_for_user(user_id)\n",
    "    precision = calculate_precision(user_id, recommended_items, test_df)\n",
    "    recall = calculate_recall(user_id, recommended_items, test_df)\n",
    "    f1 = calculate_f1_score(user_id, recommended_items, test_df)\n",
    "    hit = calculate_hit_ratio(user_id, recommended_items, test_df)\n",
    "    known_user_metrics.append((user_id, precision, recall, f1, hit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e861ccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metriche per gli utenti noti:\n",
      "Precisione media: 0.0120\n",
      "Recall medio: 0.0079\n",
      "F1-Score medio: 0.0090\n",
      "Hit Ratio medio: 0.1200\n"
     ]
    }
   ],
   "source": [
    "# Calcola la media delle metriche per gli utenti noti\n",
    "if len(known_user_metrics) > 0:\n",
    "    avg_precision_known = np.mean([metric[1] for metric in known_user_metrics])\n",
    "    avg_recall_known = np.mean([metric[2] for metric in known_user_metrics])\n",
    "    avg_f1_known = np.mean([metric[3] for metric in known_user_metrics])\n",
    "    avg_hit_known = np.mean([metric[4] for metric in known_user_metrics])\n",
    "else:\n",
    "    avg_precision_known, avg_recall_known, avg_f1_known = 0, 0, 0\n",
    "\n",
    "# Stampa i risultati per gli utenti noti\n",
    "print(\"Metriche per gli utenti noti:\")\n",
    "print(f\"Precisione media: {avg_precision_known:.4f}\")\n",
    "print(f\"Recall medio: {avg_recall_known:.4f}\")\n",
    "print(f\"F1-Score medio: {avg_f1_known:.4f}\")\n",
    "print(f\"Hit Ratio medio: {avg_hit_known:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363350cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
